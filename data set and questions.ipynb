{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/python\n",
    "\n",
    "\"\"\" \n",
    "    Starter code for exploring the Enron dataset (emails + finances);\n",
    "    loads up the dataset (pickled dict of dicts).\n",
    "\n",
    "    The dataset has the form:\n",
    "    enron_data[\"LASTNAME FIRSTNAME MIDDLEINITIAL\"] = { features_dict }\n",
    "\n",
    "    {features_dict} is a dictionary of features associated with that person.\n",
    "    You should explore features_dict as part of the mini-project,\n",
    "    but here's an example to get you started:\n",
    "\n",
    "    enron_data[\"SKILLING JEFFREY K\"][\"bonus\"] = 5600000\n",
    "    \n",
    "\"\"\"\n",
    "\n",
    "import pickle\n",
    "\n",
    "enron_data = pickle.load(open(\"C:/Users/Jon Targaryen/Desktop/mach learn/ud120-projects/final_project/final_project_dataset.pkl\", \"r\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Info**:  The aggregated Enron email + financial dataset is stored in a dictionary, where each key in the dictionary is a \n",
    "person’s name and the value is a dictionary containing all the features of that person.The email + finance (E+F) data dictionary\n",
    "is stored as a pickle file,which is a handy way to store and load python objects directly. \n",
    "Use datasets_questions/explore_enron_data.py to load the dataset.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "146\n"
     ]
    }
   ],
   "source": [
    "# How many data points (people) are in the dataset?\n",
    "\n",
    "print len(enron_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('METTS MARK', 21)\n",
      "('BAXTER JOHN C', 21)\n",
      "('ELLIOTT STEVEN', 21)\n",
      "('CORDES WILLIAM R', 21)\n",
      "('HANNON KEVIN P', 21)\n",
      "('MORDAUNT KRISTINA M', 21)\n",
      "('MEYER ROCKFORD G', 21)\n",
      "('MCMAHON JEFFREY', 21)\n",
      "('HORTON STANLEY C', 21)\n",
      "('PIPER GREGORY F', 21)\n",
      "('HUMPHREY GENE E', 21)\n",
      "('UMANOFF ADAM S', 21)\n",
      "('BLACHMAN JEREMY M', 21)\n",
      "('SUNDE MARTIN', 21)\n",
      "('GIBBS DANA R', 21)\n",
      "('LOWRY CHARLES P', 21)\n",
      "('COLWELL WESLEY', 21)\n",
      "('MULLER MARK S', 21)\n",
      "('JACKSON CHARLENE R', 21)\n",
      "('WESTFAHL RICHARD K', 21)\n",
      "('WALTERS GARETH W', 21)\n",
      "('WALLS JR ROBERT H', 21)\n",
      "('KITCHEN LOUISE', 21)\n",
      "('CHAN RONNIE', 21)\n",
      "('BELFER ROBERT', 21)\n",
      "('SHANKMAN JEFFREY A', 21)\n",
      "('WODRASKA JOHN', 21)\n",
      "('BERGSIEKER RICHARD P', 21)\n",
      "('URQUHART JOHN A', 21)\n",
      "('BIBI PHILIPPE A', 21)\n",
      "('RIEKER PAULA H', 21)\n",
      "('WHALEY DAVID A', 21)\n",
      "('BECK SALLY W', 21)\n",
      "('HAUG DAVID L', 21)\n",
      "('ECHOLS JOHN B', 21)\n",
      "('MENDELSOHN JOHN', 21)\n",
      "('HICKERSON GARY J', 21)\n",
      "('CLINE KENNETH W', 21)\n",
      "('LEWIS RICHARD', 21)\n",
      "('HAYES ROBERT E', 21)\n",
      "('MCCARTY DANNY J', 21)\n",
      "('KOPPER MICHAEL J', 21)\n",
      "('LEFF DANIEL P', 21)\n",
      "('LAVORATO JOHN J', 21)\n",
      "('BERBERIAN DAVID', 21)\n",
      "('DETMERING TIMOTHY J', 21)\n",
      "('WAKEHAM JOHN', 21)\n",
      "('POWERS WILLIAM', 21)\n",
      "('GOLD JOSEPH', 21)\n",
      "('BANNANTINE JAMES M', 21)\n",
      "('DUNCAN JOHN H', 21)\n",
      "('SHAPIRO RICHARD S', 21)\n",
      "('SHERRIFF JOHN R', 21)\n",
      "('SHELBY REX', 21)\n",
      "('LEMAISTRE CHARLES', 21)\n",
      "('DEFFNER JOSEPH M', 21)\n",
      "('KISHKILL JOSEPH G', 21)\n",
      "('WHALLEY LAWRENCE G', 21)\n",
      "('MCCONNELL MICHAEL S', 21)\n",
      "('PIRO JIM', 21)\n",
      "('DELAINEY DAVID W', 21)\n",
      "('SULLIVAN-SHAKLOVITZ COLLEEN', 21)\n",
      "('WROBEL BRUCE', 21)\n",
      "('LINDHOLM TOD A', 21)\n",
      "('MEYER JEROME J', 21)\n",
      "('LAY KENNETH L', 21)\n",
      "('BUTTS ROBERT H', 21)\n",
      "('OLSON CINDY K', 21)\n",
      "('MCDONALD REBECCA', 21)\n",
      "('CUMBERLAND MICHAEL S', 21)\n",
      "('GAHN ROBERT S', 21)\n",
      "('MCCLELLAN GEORGE', 21)\n",
      "('HERMANN ROBERT J', 21)\n",
      "('SCRIMSHAW MATTHEW', 21)\n",
      "('GATHMANN WILLIAM D', 21)\n",
      "('HAEDICKE MARK E', 21)\n",
      "('BOWEN JR RAYMOND M', 21)\n",
      "('GILLIS JOHN', 21)\n",
      "('FITZGERALD JAY L', 21)\n",
      "('MORAN MICHAEL P', 21)\n",
      "('REDMOND BRIAN L', 21)\n",
      "('BAZELIDES PHILIP J', 21)\n",
      "('BELDEN TIMOTHY N', 21)\n",
      "('DURAN WILLIAM D', 21)\n",
      "('THORN TERENCE H', 21)\n",
      "('FASTOW ANDREW S', 21)\n",
      "('FOY JOE', 21)\n",
      "('CALGER CHRISTOPHER F', 21)\n",
      "('RICE KENNETH D', 21)\n",
      "('KAMINSKI WINCENTY J', 21)\n",
      "('LOCKHART EUGENE E', 21)\n",
      "('COX DAVID', 21)\n",
      "('OVERDYKE JR JERE C', 21)\n",
      "('PEREIRA PAULO V. FERRAZ', 21)\n",
      "('STABLER FRANK', 21)\n",
      "('SKILLING JEFFREY K', 21)\n",
      "('BLAKE JR. NORMAN P', 21)\n",
      "('SHERRICK JEFFREY B', 21)\n",
      "('PRENTICE JAMES', 21)\n",
      "('GRAY RODNEY', 21)\n",
      "('PICKERING MARK R', 21)\n",
      "('THE TRAVEL AGENCY IN THE PARK', 21)\n",
      "('NOLES JAMES L', 21)\n",
      "('KEAN STEVEN J', 21)\n",
      "('TOTAL', 21)\n",
      "('FOWLER PEGGY', 21)\n",
      "('WASAFF GEORGE', 21)\n",
      "('WHITE JR THOMAS E', 21)\n",
      "('CHRISTODOULOU DIOMEDES', 21)\n",
      "('ALLEN PHILLIP K', 21)\n",
      "('SHARP VICTORIA T', 21)\n",
      "('JAEDICKE ROBERT', 21)\n",
      "('WINOKUR JR. HERBERT S', 21)\n",
      "('BROWN MICHAEL', 21)\n",
      "('BADUM JAMES P', 21)\n",
      "('HUGHES JAMES A', 21)\n",
      "('REYNOLDS LAWRENCE', 21)\n",
      "('DIMICHELE RICHARD G', 21)\n",
      "('BHATNAGAR SANJAY', 21)\n",
      "('CARTER REBECCA C', 21)\n",
      "('BUCHANAN HAROLD G', 21)\n",
      "('YEAP SOON', 21)\n",
      "('MURRAY JULIA H', 21)\n",
      "('GARLAND C KEVIN', 21)\n",
      "('DODSON KEITH', 21)\n",
      "('YEAGER F SCOTT', 21)\n",
      "('HIRKO JOSEPH', 21)\n",
      "('DIETRICH JANET R', 21)\n",
      "('DERRICK JR. JAMES V', 21)\n",
      "('FREVERT MARK A', 21)\n",
      "('PAI LOU L', 21)\n",
      "('BAY FRANKLIN R', 21)\n",
      "('HAYSLETT RODERICK J', 21)\n",
      "('FUGH JOHN L', 21)\n",
      "('FALLON JAMES B', 21)\n",
      "('KOENIG MARK E', 21)\n",
      "('SAVAGE FRANK', 21)\n",
      "('IZZO LAWRENCE L', 21)\n",
      "('TILNEY ELIZABETH A', 21)\n",
      "('MARTIN AMANDA K', 21)\n",
      "('BUY RICHARD B', 21)\n",
      "('GRAMM WENDY L', 21)\n",
      "('CAUSEY RICHARD A', 21)\n",
      "('TAYLOR MITCHELL S', 21)\n",
      "('DONAHUE JR JEFFREY M', 21)\n",
      "('GLISAN JR BEN F', 21)\n"
     ]
    }
   ],
   "source": [
    "# For each person, how many features are available?\n",
    "# features in data set\n",
    "\n",
    "for key, value in enron_data.items():\n",
    "    #print value\n",
    "    print(key, len(filter(bool, value)))\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Info**:   The “poi” feature records whether the person is a person of interest, according to our definition. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " # POI is 18 \n"
     ]
    }
   ],
   "source": [
    "# How many POIs are there in the E+F dataset?\n",
    "\n",
    "counter = 0\n",
    "for i in enron_data.values():\n",
    "    if i['poi'] == True:\n",
    "        counter+=1\n",
    "print \" # POI is %d \" %counter   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Info**: We compiled a list of all POI names (in ../final_project/poi_names.txt) and associated email addresses (in ../final_project/poi_email_addresses.py).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Total number of POIs: ', 35)\n"
     ]
    }
   ],
   "source": [
    "# How many POI’s were there total? \n",
    "# (Use the names file, not the email addresses, since many folks have more than one address and a few didn’t work for Enron, \n",
    "# so we don’t have their emails.)\n",
    "\n",
    "poi_name_record = open(\"C:/Users/Jon Targaryen/Desktop/mach learn/ud120-projects/final_project/poi_names.txt\").read().split(\"\\n\")\n",
    "\n",
    "poi_name_total = [record for record in poi_name_record if \"(y)\" in record or \"(n)\" in record]\n",
    "\n",
    "print(\"Total number of POIs: \", len(poi_name_total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Main thought is about having enough data to really learn the patterns.  In general, more data is always better--only having 18 data points doesn't give you that many examples to learn from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1095040"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What is the total value of the stock belonging to James Prentice?\n",
    "\n",
    "enron_data[\"PRENTICE JAMES\"][\"total_stock_value\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How many email messages do we have from Wesley Colwell to persons of interest?\n",
    "enron_data[\"COLWELL WESLEY\"][\"from_this_person_to_poi\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19250000"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What’s the value of stock options exercised by Jeffrey K Skilling?\n",
    "\n",
    "enron_data[\"SKILLING JEFFREY K\"][\"exercised_stock_options\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['LAY KENNETH L', 103559793, 'FASTOW ANDREW S', 2424083, 'SKILLING JEFFREY K', 8682716]\n"
     ]
    }
   ],
   "source": [
    "# Of these three individuals (Lay, Skilling and Fastow), who took home the most money\n",
    "# (largest value of “total_payments” feature)?\n",
    "# How much money did that person get?\n",
    "\n",
    "mykeys = [\"SKILLING JEFFREY K\",\"LAY KENNETH L\",\"FASTOW ANDREW S\"]\n",
    "tot_value = list()\n",
    "for key, value in enron_data.iteritems():\n",
    "    if key in mykeys:\n",
    "        tot_value = tot_value + [key,value[\"total_payments\"]]\n",
    "print tot_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "people who have a quantified salary: 95\n",
      "people who have an email address: 111\n"
     ]
    }
   ],
   "source": [
    "# How many folks in this dataset have a quantified salary? What about a known email address?\n",
    "\n",
    "count = 0\n",
    "for key, value in enron_data.iteritems():\n",
    "    if value[\"salary\"]!='NaN':\n",
    "        count += 1\n",
    "print \"people who have a quantified salary: \" + str(count)\n",
    "\n",
    "count1 = 0\n",
    "for key, value in enron_data.iteritems():\n",
    "    if value[\"email_address\"]!='NaN':\n",
    "        count1+= 1\n",
    "print \"people who have an email address: \" + str(count1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "95 have a quantified salary. 111 have a known email address."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **INFO**: A python dictionary can’t be read directly into an sklearn classification or regression algorithm; instead, it needs a numpy array or a list of lists (each element of the list (itself a list) is a data point, and the elements of the smaller list are the features of that point).\n",
    "We’ve written some helper functions (featureFormat() and targetFeatureSplit() in tools/feature_format.py) that can take a list of feature names and the data dictionary, and return a numpy array.\n",
    "In the case when a feature does not have a value for a particular person, this function will also replace the feature value with 0 (zero)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you saw a little while ago, not every POI has an entry in the dataset (e.g. Michael Krautz). That’s because the dataset was created using the financial data you can find in final_project/enron61702insiderpay.pdf, which is missing some POI’s (those absences propagated through to the final dataset). On the other hand, for many of these “missing” POI’s, we do have emails.\n",
    "\n",
    "While it would be straightforward to add these POI’s and their email information to the E+F dataset, and just put “NaN” for their financial information, this could introduce a subtle problem. I will walk through that here.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "people in set with no number of their payments: 21\n",
      "percentage of people in the set with payment value missing: 14.3835616438\n"
     ]
    }
   ],
   "source": [
    "# How many people in the E+F dataset (as it currently exists) have “NaN” for their total payments? \n",
    "# What percentage of people in the dataset as a whole is this?\n",
    "\n",
    "count2 = 0\n",
    "for key, value in enron_data.iteritems():\n",
    "    if value[\"total_payments\"]=='NaN':\n",
    "        count2 += 1\n",
    "print \"people in set with no number of their payments: \" + str(count2)\n",
    "\n",
    "print \"percentage of people in the set with payment value missing: \" + str(float(count2)/len(enron_data)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " 21 out of 146 (about 14%) of the people in the dataset don't have \"total_payments\" filled in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POI is 18 \n",
      "POI people in set with no number of their payments: 0\n",
      "Percentage of POI people in the set with payment value missing: 0.0\n"
     ]
    }
   ],
   "source": [
    "# How many POIs in the E+F dataset have “NaN” for their total payments? \n",
    "# What percentage of POI’s as a whole is this?\n",
    "\n",
    "\n",
    "# number of pois\n",
    "\n",
    "counter = 0\n",
    "for i in enron_data.values():\n",
    "    if i['poi'] == True:\n",
    "        counter+=1\n",
    "print \"POI is %d \" %counter  \n",
    "\n",
    "\n",
    "# pois with 'NaN' payments\n",
    "count3 = 0\n",
    "for key, value in enron_data.iteritems():\n",
    "    if value[\"poi\"]=='True':\n",
    "        if value[\"total_payments\"]=='NaN':\n",
    "            count3 += 1\n",
    "print \"POI people in set with no number of their payments: \" + str(count3)\n",
    "\n",
    "print \"Percentage of POI people in the set with payment value missing: \" + str(float(count3)/len(enron_data)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0 out of 18, or 0% of POI's don't have total_payments filled."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If a machine learning algorithm were to use \"total_payments\" as a feature, \n",
    "would you expect it to associate a “NaN” value with POIs or non-POIs?\n",
    "\n",
    "No training points would have \"NaN\" for total_payments when the class label is \"POI\".\n",
    "The \"NaN\" would be associated with non-POIs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you added in, say, 10 more data points which were all POI’s, and put “NaN” for the total payments for those folks, \n",
    "the numbers you just calculated would change.\n",
    "What is the new number of people of the dataset? What is the new number of folks with “NaN” for total payments?\n",
    "\n",
    "\n",
    "New number of people of the dataset = 146 + 10 = 156.\n",
    "\n",
    "People in set with no number of their payments =  21 + 10 = 31.\n",
    "\n",
    "\n",
    "Now there are 156 folks in dataset, 31 of whom have \"NaN\" total_payments. \n",
    "\n",
    "This makes for 31/156 = 19.87 % of them with a \"NaN\" overall.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the new number of POI’s in the dataset? What is the new number of POI’s with NaN for total_payments?\n",
    "\n",
    "New number of POI's in the data set = 18 + 10 = 28.\n",
    "\n",
    "New number of POI’s with NaN for total_payments = 0 + 10 = 10.\n",
    "\n",
    "POI + 'NaN' payment values = 10/28 = 35.71 % .\n",
    "\n",
    "\n",
    "That's 36% of the POI's who have \"NaN\" for total_payments, a big jump from before."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the new data points are added, do you think a supervised classification algorithm might interpret “NaN” for total_payments as a clue that someone is a POI?\n",
    "\n",
    "Yes, it totally could.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding in the new POI’s in this example, none of whom we have financial information for, has introduced a subtle problem, that our lack of financial information about them can be picked up by an algorithm as a clue that they’re POIs. Another way to think about this is that there’s now a difference in how we generated the data for our two classes--non-POIs all come from the financial spreadsheet, while many POIs get added in by hand afterwards. That difference can trick us into thinking we have better performance than we do--suppose you use your POI detector to decide whether a new, unseen person is a POI, and that person isn’t on the spreadsheet. Then all their financial data would contain “NaN” but the person is very likely not a POI (there are many more non-POIs than POIs in the world, and even at Enron)--you’d be likely to accidentally identify them as a POI, though!\n",
    "\n",
    "For now, the takeaway message is to be very careful about introducing features that come from different sources depending on the class! It’s a classic way to accidentally introduce biases and mistakes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
